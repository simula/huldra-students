# Md Rizve Hasan - Validating Accessibility in Crowdsourced Multimedia Survey Frameworks

This thesis has studied the influence of accessibility conditions on the validity and reliability of crowdsourced online surveys in the Huldra framework. With the growing usage of digital-based surveys for data collection, ensuring universal accessibility and data integrity can be challenging. Four pre-survey validation tests (the Ishihara Color Vision Test, Screen Contrast Test, Audio Quality Assessment, and Background Noise Evaluation) are developed and administered via empirically based studies to identify and address a range of biases due to perceptual limitations and device heterogeneity.

Results from studies showed that 21 participants with visual and 28 audio surveys provided insight into significant differences in performance based on accessible factors. Those with color vision deficiencies were significantly worse (2.25/4 vs. 3.46/4) and perceived higher task difficulty (8.38/10 vs. 5.23/10) than their counterpart with normal vision. Similarly, subjects with less than ideal audio equipment showed significantly lower comprehension in auditory tasks. These results provide empirical evidence to support the assertion that suppressed perceptual limitations can create systematic biases in survey responses and threaten data validity.

The work presents methodological developments in the validation of accessibility, evidence regarding the impact of accessibility-related response biases, and advice on constructing more inclusive survey setups in practice. Researchers can use these validation techniques to improve data quality and guarantee the participation of all kinds of users. This work contributes to developing the technical infrastructure of accessibility and larger inclusiveness projects in digital research.
